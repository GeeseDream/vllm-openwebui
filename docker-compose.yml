services:
  vllm-openai:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    image: ${VLLM_OPENAI_IMAGE}
    ports:
      - "${VLLM_OPENAI_API_PORT}:8000"
    volumes:
      - .:/root/.cache/huggingface
    command: --model ${MODEL_NAME} --api-key ${API_KEY}
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    environment:
      - OPENAI_API_BASE_URL=http://vllm-openai:8000/v1
      - OPENAI_API_KEY=${API_KEY}
    ports:
      - "${OPEN_WEBUI_PORT}:8080"
    volumes:
      - .:/app/backend/data
    depends_on:
      - vllm-openai
